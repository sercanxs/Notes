Neural Network classification with PyTorch

Classification is a problem of predicting whether something is one thing or another (there can be multiple things as the options).

Book version of this notebook - https://www.learnpytorch.io/02_pytorch_classification/
All other resources - https://github.com/mrdbourke/pytorch-deep-learning
Stuck? Ask a question - https://github.com/mrdbourke/pytorch-deep-learning/discussions


Make classification data and get it ready

import sklearn
from sklearn.datasets import make_circles

# Make 1000 samples
n_samples = 1000

# Create circles                       --> Make a large circle containing a smaller circle in 2d.
X, y = make_circles(n_samples,         --> 1000 veri ürettik.
                    noise=0.03,        --> Standard deviation of Gaussian noise added to the data.
                    random_state=42)   --> random seed ile aynı görevi yapıyor.
                                           Ekstaradan faktor de ayarlanabilir. default'u 0.8 dir. yani içerideki dairenin çapı dışarıdaki
                                           dairenin 5'te 4'üdür.
     

len(X), len(y)
     
(1000, 1000)

print(f"First 5 samples of X:\n {X[:5]}")
print(f"First 5 samples of y:\n {y[:5]}")
     
First 5 samples of X:
 [[ 0.75424625  0.23148074]
 [-0.75615888  0.15325888]
 [-0.81539193  0.17328203]
 [-0.39373073  0.69288277]
 [ 0.44220765 -0.89672343]]
First 5 samples of y:
 [1 1 1 1 0]                --> y değişkeni bir ve sıfırlardan oluşur. 1 değerlerine karşılık gelen X verileri dış daireyi 0 değerlerine
                                denk gelen X verileri iç daireyi oluşturur.

# Make DataFrame of circle data
import pandas as pd                    --> pandas kullandık
circles = pd.DataFrame({"X1": X[:, 0], 
                        "X2": X[:, 1],
                        "label": y})   --> key value girdik.
circles.head(10)                              
     
              X1	      X2    label
0	0.754246	0.231481	1
1	-0.756159	0.153259	1
2	-0.815392	0.173282	1
3	-0.393731	0.692883	1
4	0.442208	-0.896723	0
5	-0.479646	0.676435	1
6	-0.013648	0.803349	1
7	0.771513	0.147760	1
8	-0.169322	-0.793456	1
9	-0.121486	1.021509	0


circles.label.value_counts() 
     
1    500
0    500
Name: label, dtype: int64


# Visualize, visualize, visualize
import matplotlib.pyplot as plt
plt.scatter(x=X[:, 0],             --> x eksenine X değişkeninin yukarıdaki X1 kısmını koyduk.
            y=X[:, 1],             --> y eksenine X değişkeninin yukarıdaki X2 kısmını koyduk.
            c=y,                   --> c'ye ise y değişkenini label olsun diye koyduk. Yani y değerlerinin 1 olduğu noktalarda
                                       X değerleri bir renk alırken, y değerlerinin 0 olduğu noktalarda X değerleri başka renk alacak.
            cmap=plt.cm.RdYlBu);   --> RedYellowBlue'yi seçtik. Dış çember red olurken iç çember blue oldu.
     

Note: The data we're working with is often referred to as a toy dataset, a dataset that is small enough to experiment but still sizeable enough to practice the fundamentals.

-----

Check input and output shapes

X.shape, y.shape
     
((1000, 2), (1000,))

X
     
array([[ 0.75424625,  0.23148074],
       [-0.75615888,  0.15325888],
       [-0.81539193,  0.17328203],
       ...,
       [-0.13690036, -0.81001183],
       [ 0.67036156, -0.76750154],
       [ 0.28105665,  0.96382443]])

View the first example of features and labels
X_sample = X[0]
y_sample = y[0]

print(f"Values for one sample of X: {X_sample} and the same for y: {y_sample}")
print(f"Shapes for one sample of X: {X_sample.shape} and the same for y: {y_sample.shape}")
     
Values for one sample of X: [0.75424625 0.23148074] and the same for y: 1
Shapes for one sample of X: (2,) and the same for y: ()


Turn data into tensors and create train and test splits

import torch
torch.__version__
     
'1.10.0+cu111'

type(X), X.dtype --> (numpy.ndarray, dtype('float64'))

# Turn data into tensors
X = torch.from_numpy(X).type(torch.float)
y = torch.from_numpy(y).type(torch.float)

X[:5], y[:5]
     
(tensor([[ 0.7542,  0.2315],
         [-0.7562,  0.1533],
         [-0.8154,  0.1733],
         [-0.3937,  0.6929],
         [ 0.4422, -0.8967]]), tensor([1., 1., 1., 1., 0.]))



type(X), X.dtype, y.dtype --> (torch.Tensor, torch.float32, torch.float32)

# Split data into training and test sets

from sklearn.model_selection import train_test_split   --> train_test_split splits arrays or matrices into random train and test subsets.

X_train, X_test, y_train, y_test = train_test_split(X, --> X değişkenini buraya yazdık. Soldaki değişkenler bu sırayla yazılmalılar --> X_train, X_test, y_train, y_test                             			           
                                                    y, --> y değişkenini buraya yazdık.
                                                    test_size=0.2, # 0.2 = 20% of data will be test & 80% will be train
                                                    random_state=42) --> random seed ile aynı görevi yapıyor.
     

len(X_train), len(X_test), len(y_train), len(y_test)
     
(800, 200, 800, 200)

n_samples
     
1000

--------------------------------------------------------

Building a model
Let's build a model to classify our blue and red dots.

To do so, we want to:

Setup device agonistic code so our code will run on an accelerator (GPU) if there is one
Construct a model (by subclassing nn.Module)
Define a loss function and optimizer
Create a training and test loop

# Import PyTorch and nn
import torch
from torch import nn

# Make device agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"
device                                                 --> cpu
     


X_train

tensor([[ 0.6579, -0.4651],
        [ 0.6319, -0.7347],
        [-1.0086, -0.1240],
        ...,
        [ 0.0157, -1.0300],
        [ 1.0110,  0.1680],
        [ 0.5578, -0.5709]])


--------------------------------------------------------

Now we've setup device agnostic code, let's create a model that:

Subclasses nn.Module (almost all models in PyTorch subclass nn.Module)
Create 2 nn.Linear() layers that are capable of handling the shapes of our data
Defines a forward() method that outlines the forward pass (or forward computation) of the model
Instatiate an instance of our model class and send it to the target device

X_train.shape
     
torch.Size([800, 2])

y_train[:5]
     
tensor([1., 0., 0., 0., 1.])

from sklearn import datasets
# 1. Construct a model that subclasses nn.Module
class CircleModelV0(nn.Module):
  def __init__(self):
    super().__init__()
    # 2. Create 2 nn.Linear layers capable of handling the shapes of our data                                 --> 2 tane nn.Linear koyunca multi layer neural network oluşturmuş olduk.
    self.layer_1 = nn.Linear(in_features=2, out_features=5) # takes in 2 features and upscales to 5 features  --> 5 sayısı diğer nn.Linear'e gider ve yüksek değer vermek modelin kalitesini yükseltir ama yavaşlık sorunu oluşur.
    self.layer_2 = nn.Linear(in_features=5, out_features=1) # takes in 5 features from previous layer and outputs a single feature (same shape as y)
                                                                                                              Buradaki 2 değeri input layerindeki 2 neuron'i temsil ediyor.
                                                                                                                       5 değeri hidden layerdeki 5 neuron'i temsil ediyor.
														       1 değeri output layerindeki outputu temsil ediyor.
                                                                                                                     

  # 3. Define a forward() method that outlines the forward pass
  def forward(self, x):
    return self.layer_2(self.layer_1(x)) # x -> layer_1 ->  layer_2 -> output 
                                        layer 1'de linear regression formülü uygulanıyor output layer 2'ye gidiyor. layer 2'de linear regression formülü uygulanıyor.
                                        output return ediliyor.
                                                                                 

# 4. Instantiate an instance of our model class and send it to the target device
model_0 = CircleModelV0().to(device)
model_0
     
CircleModelV0(
  (layer_1): Linear(in_features=2, out_features=5, bias=True)
  (layer_2): Linear(in_features=5, out_features=1, bias=True)
)

device
     
cpu

next(model_0.parameters()).device
     
device(type='cpu')


-----


# Let's replicate the model above using nn.Sequential() --> sequential ile yukarıdaki kurduğumuz modeli kurabiliriz. Ama nn.module'i extend ettiğimiz yukarıdaki modelde 
							    forward methodunda istediğimizi yapabiliriz. Sequential sadece yukarı modeldeki gibi sıralamaya izin verir.
model_0 = nn.Sequential(
    nn.Linear(in_features=2, out_features=5),
    nn.Linear(in_features=5, out_features=1)
).to(device)

model_0
     
Sequential(
  (0): Linear(in_features=2, out_features=5, bias=True)
  (1): Linear(in_features=5, out_features=1, bias=True)
)

model_0.state_dict()
     
OrderedDict([('0.weight', tensor([[-0.1962,  0.3652],
                      [ 0.2764,  0.2147],
                      [ 0.5723, -0.5955],
                      [-0.2329,  0.0170],
                      [ 0.6259,  0.6916]], device='cuda:0')),
             ('0.bias',
              tensor([ 0.4193,  0.6624,  0.2594, -0.1640, -0.0477], device='cuda:0')),
             ('1.weight',
              tensor([[ 0.4129,  0.2358,  0.4115,  0.4045, -0.0853]], device='cuda:0')),
             ('1.bias', tensor([-0.4294], device='cuda:0'))])


# Make predictions
with torch.inference_mode():
  untrained_preds = model_0(X_test.to(device))

print(f"Length of predictions: {len(untrained_preds)}, Shape: {untrained_preds.shape}")
print(f"Length of test samples: {len(X_test)}, Shape: {X_test.shape}")
print(f"\nFirst 10 predictions:\n{torch.round(untrained_preds[:10])}") --> sonuçları yuvarladık.
print(f"\nFirst 10 labels:\n{y_test[:10]}")
     
Length of predictions: 200, Shape: torch.Size([200, 1])
Length of test samples: 200, Shape: torch.Size([200, 2]) --> len soldaki değeri verir. Buranın lengthi 200. 

First 10 predictions:
tensor([[-0.],
        [-0.],
        [-0.],
        [-0.],
        [0.],
        [0.],
        [-0.],
        [-0.],
        [-0.],
        [-0.]], device='cuda:0')

First 10 labels:
tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0.])



X_test[:10], y_test[:10]
     
(tensor([[-0.3752,  0.6827],
         [ 0.0154,  0.9600],
         [-0.7028, -0.3147],
         [-0.2853,  0.9664],
         [ 0.4024, -0.7438],
         [ 0.6323, -0.5711],
         [ 0.8561,  0.5499],
         [ 1.0034,  0.1903],
         [-0.7489, -0.2951],
         [ 0.0538,  0.9739]]),
 tensor([1., 0., 1., 0., 1., 1., 0., 0., 1., 0.]))


--------------------------------------------------------









